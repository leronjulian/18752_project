{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA_MLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgkNEo6yoRQu"
      },
      "source": [
        "import librosa\n",
        "import matplotlib.pyplot as plt \n",
        "import librosa.display as libDisp\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn import svm\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# MLP Model\n",
        "MLP_model = MLPClassifier(hidden_layer_sizes=100, solver='sgd', learning_rate_init=0.01, max_iter=500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM1YA6OaozRM"
      },
      "source": [
        "notes = []\n",
        "for i in range(5, 7):\n",
        "    for note in ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']:\n",
        "        notes.append(f'{note}{i}')\n",
        "\n",
        "mapping = {i: notes[i] for i in range(len(notes))}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4seC6Wfo62d"
      },
      "source": [
        "def run_note(X, note_no, y):\n",
        "  X_transformed = None\n",
        "  targets = None\n",
        "  note_name = mapping[note_no]\n",
        "  targets = y[:, note_no]\n",
        "  \n",
        "  if len(np.unique(targets)) < 2:\n",
        "    return X_transformed, targets\n",
        "\n",
        "  lda = LinearDiscriminantAnalysis(n_components=1)\n",
        "  X_transformed  = lda.fit_transform(X, targets)\n",
        "\n",
        "  return X_transformed, targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9r7xiPvo8ZB",
        "outputId": "e828968f-5107-45e6-b6e6-6aec136cead9"
      },
      "source": [
        "# Train Model\n",
        "train_acc = []\n",
        "train_idx = ['1', '2', '4', '6', '7', '9']\n",
        "for idx in train_idx:\n",
        "  file_name = 'song' + idx\n",
        "  a = np.load(file_name + '.npz', allow_pickle=True)\n",
        "\n",
        "  b = a['arr_0']\n",
        "  b = b.sum(axis=0)\n",
        "\n",
        "  X = b['X']\n",
        "  y = b['y']\n",
        "\n",
        "  for i in range(len(notes)):\n",
        "    X_t, y_cur = run_note(X, i, y)\n",
        "    if np.any(X_t) != None:\n",
        "      MLP_model.fit(X_t, y_cur) #Trains the model\n",
        "      acc = MLP_model.score(X_t, y_cur) \n",
        "      train_acc.append(acc)\n",
        "\n",
        "print('Done Training...')\n",
        "print('Accuracy on Test Set', np.mean(train_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done Training...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4SpEN0so-Dt",
        "outputId": "8e626050-68c3-4e42-f076-9ca81e9428f7"
      },
      "source": [
        "'''\n",
        "  Save model\n",
        "'''\n",
        "filename = 'LDA_MLP_classification.sav'\n",
        "joblib.dump(MLP_model, filename)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['LDA_MLP_classification.sav']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCx_cUy2qLKp",
        "outputId": "084c7a6a-8582-42e0-e01b-eeb2e0c84c42"
      },
      "source": [
        "'''\n",
        "  Valid Data\n",
        "'''\n",
        "valid_acc = []\n",
        "loaded_model = joblib.load('LDA_MLP_classification.sav')\n",
        "\n",
        "def run_note(X, note_no, y):\n",
        "  X_transformed = None\n",
        "  targets = None\n",
        "  note_name = mapping[note_no]\n",
        "  targets = y[:, note_no]\n",
        "  \n",
        "  if len(np.unique(targets)) < 2:\n",
        "    return X_transformed, targets\n",
        "\n",
        "  lda = LinearDiscriminantAnalysis(n_components=1)\n",
        "  X_transformed  = lda.fit_transform(X, targets)\n",
        "\n",
        "  return X_transformed, targets\n",
        "\n",
        "\n",
        "valid_idx = ['8', '10']\n",
        "for idx in valid_idx:\n",
        "\n",
        "  file_name = 'song' + idx\n",
        "  a = np.load(file_name + '.npz', allow_pickle=True)\n",
        "\n",
        "  b = a['arr_0']\n",
        "  b = b.sum(axis=0)\n",
        "\n",
        "  X = b['X']\n",
        "  y = b['y']\n",
        "\n",
        "\n",
        "\n",
        "  for i in range(len(notes)):\n",
        "    X_t, y_cur = run_note(X, i, y)\n",
        "    if np.any(X_t) != None:\n",
        "      X_test = X_t[:,0].reshape((X_t[:,0].shape[0], 1))\n",
        "      pred = loaded_model.predict(X_test)\n",
        "      acc = loaded_model.score(X_test, y_cur) \n",
        "      valid_acc.append(acc)\n",
        "\n",
        "\n",
        "print('Accuracy on Validation Set', np.mean(valid_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.957315862616637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAfRnITCqPdM",
        "outputId": "c77f7ead-f968-42fe-8398-22de05d549cd"
      },
      "source": [
        "'''\n",
        "  Test Data\n",
        "'''\n",
        "\n",
        "test_acc = []\n",
        "loaded_model = joblib.load('LDA_MLP_classification.sav')\n",
        "\n",
        "def run_note(X, note_no, y):\n",
        "  X_transformed = None\n",
        "  targets = None\n",
        "  note_name = mapping[note_no]\n",
        "  targets = y[:, note_no]\n",
        "  \n",
        "  if len(np.unique(targets)) < 2:\n",
        "    # print(f\"note {note_name} has no samples\")\n",
        "    return X_transformed, targets\n",
        "\n",
        "  lda = LinearDiscriminantAnalysis(n_components=1)\n",
        "  X_transformed  = lda.fit_transform(X, targets)\n",
        "\n",
        "  return X_transformed, targets\n",
        "\n",
        "\n",
        "test_idx = ['3', '5']\n",
        "for idx in test_idx:\n",
        "\n",
        "  file_name = 'song' + idx\n",
        "  a = np.load(file_name + '.npz', allow_pickle=True)\n",
        "\n",
        "  b = a['arr_0']\n",
        "  b = b.sum(axis=0)\n",
        "\n",
        "  X = b['X']\n",
        "  y = b['y']\n",
        "\n",
        "\n",
        "  # Test\n",
        "  for i in range(len(notes)):\n",
        "    X_t, y_cur = run_note(X, i, y)\n",
        "    if np.any(X_t) != None:\n",
        "      X_test = X_t[:,0].reshape((X_t[:,0].shape[0], 1))\n",
        "      acc = loaded_model.score(X_test, y_cur)\n",
        "      test_acc.append(acc)\n",
        "      \n",
        "print('Accuracy on Test Set', np.mean(test_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9165952607637788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1KYtgWRFMX3",
        "outputId": "196b6ff0-25fb-4b9e-dd16-e660e61ec9bb"
      },
      "source": [
        "'''\n",
        "  Runs Demo to print out predicted notes from a song using MLP model\n",
        "'''\n",
        "\n",
        "idx = '5'\n",
        "file_name = 'song' + idx\n",
        "a = np.load(file_name + '.npz', allow_pickle=True)\n",
        "\n",
        "b = a['arr_0']\n",
        "b = b.sum(axis=0)\n",
        "\n",
        "X = b['X']\n",
        "y = b['y']\n",
        "\n",
        "\n",
        "target_notes = []\n",
        "\n",
        "def map_notes(X, note_no, y):\n",
        "  note_name = mapping[note_no]\n",
        "  targets = y[:, note_no]\n",
        "  target_notes.append(targets)\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(notes)):\n",
        "  map_notes(X, i, y)\n",
        "\n",
        "\n",
        "target_notes = np.array(target_notes)\n",
        "# print(target_notes.shape)\n",
        "\n",
        "\n",
        "gt_notes_played = []\n",
        "for curr_note in range(target_notes.shape[1]):\n",
        "  curr_note_played = []\n",
        "  curr_pos = target_notes[:, curr_note]\n",
        "  for j in range(len(curr_pos)):\n",
        "    if curr_pos[j] == 1:\n",
        "      curr_note_played.append(mapping[j])\n",
        "\n",
        "  gt_notes_played.append(curr_note_played)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "  Test on Predict Data\n",
        "'''\n",
        "\n",
        "test_acc = []\n",
        "loaded_model = joblib.load('LDA_MLP_classification.sav')\n",
        "\n",
        "def run_note(X, note_no, y):\n",
        "  X_transformed = None\n",
        "  targets = None\n",
        "  note_name = mapping[note_no]\n",
        "  targets = y[:, note_no]\n",
        "  \n",
        "  # if len(np.unique(targets)) < 2:\n",
        "  if len(np.unique(targets)) < 2:\n",
        "    # print(f\"note {note_name} has no samples\")\n",
        "    return X_transformed, targets\n",
        "\n",
        "  lda = LinearDiscriminantAnalysis(n_components=1)\n",
        "  X_transformed  = lda.fit_transform(X, targets)\n",
        "\n",
        "  return X_transformed, targets\n",
        "\n",
        "\n",
        "# test_idx = ['3', '5']\n",
        "test_idx = ['5']\n",
        "\n",
        "pred_notes = []\n",
        "for idx in test_idx:\n",
        "\n",
        "  file_name = 'song' + idx\n",
        "  a = np.load(file_name + '.npz', allow_pickle=True)\n",
        "\n",
        "  b = a['arr_0']\n",
        "  b = b.sum(axis=0)\n",
        "\n",
        "  X = b['X']\n",
        "  y = b['y']\n",
        "\n",
        "\n",
        "  # Test\n",
        "  for i in range(len(notes)):\n",
        "    X_t, y_cur = run_note(X, i, y)\n",
        "\n",
        "\n",
        "\n",
        "    if np.any(X_t) != None:\n",
        "      # X_test = X_t[:,0].reshape((X_t[:,0].shape[0], 1))\n",
        "      X_test = X_t\n",
        "      pred = loaded_model.predict(X_test)\n",
        "      acc = loaded_model.score(X_test, y_cur) \n",
        "\n",
        "      pred_notes.append(pred)\n",
        "\n",
        "\n",
        "    else:\n",
        "      pred_notes.append(np.zeros((X_test.shape[0],)))\n",
        "\n",
        "\n",
        "pred_notes = np.array(pred_notes)\n",
        "\n",
        "pred_notes_played = []\n",
        "for curr_note in range(pred_notes.shape[1]):\n",
        "  curr_note_played = []\n",
        "  curr_pos = pred_notes[:, curr_note]\n",
        "  \n",
        "  for j in range(len(curr_pos)):\n",
        "    if curr_pos[j] == 1:\n",
        "      curr_note_played.append(mapping[j])\n",
        "      # print(mapping[j])\n",
        "      # input('s')\n",
        "\n",
        "\n",
        "  pred_notes_played.append(curr_note_played)\n",
        "\n",
        "print((gt_notes_played))\n",
        "print((pred_notes_played))   \n",
        "\n",
        "a = gt_notes_played\n",
        "b = (pred_notes_played)\n",
        "\n",
        "res = np.where(np.equal(a, b))\n",
        "\n",
        "# print(res)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['D4', 'G5'], ['D4', 'A5'], ['A5'], ['A4', 'A5'], ['A4'], ['D5'], ['A4', 'D5'], ['D5', 'E5'], ['A4', 'D5'], ['D5'], ['D5', 'G5'], ['D5', 'A5'], ['D5', 'A5'], ['D5'], ['D5'], ['D4', 'G5'], ['D4', 'A5'], ['A4', 'A5'], ['D4', 'A4'], ['A4', 'B4'], ['B4'], ['D4', 'G5'], ['D4', 'A5'], ['D4', 'A4', 'A5'], ['A4', 'A5'], ['A4'], ['A4', 'D5'], ['A4', 'D5'], ['A4', 'D5', 'E5'], ['A4', 'D5', 'E5'], ['A4', 'D5'], ['A4', 'D5', 'G5'], ['D5', 'G5'], ['D5', 'A5'], ['A4', 'D5', 'A5'], ['A4', 'A5'], ['A4'], ['A4'], ['D4'], ['D4'], ['D4', 'A4'], ['D4', 'A4'], ['D4', 'B4'], ['B4'], ['B4'], ['E4'], ['A4'], ['A4'], ['A4'], ['A4'], ['A4'], ['E4'], ['B4'], ['B4'], ['B4'], ['D4'], ['A4'], ['A4'], ['A4'], ['A4'], ['A4'], ['D4'], ['B4'], ['B4'], ['F#4'], ['B4'], ['B4'], ['B4'], ['B4'], ['B4'], ['E4'], ['A4'], ['A4'], ['B5'], ['D4', 'B5'], ['A4', 'B5'], ['A4'], ['A4', 'B5'], ['A4', 'A5'], ['A4'], ['D4'], ['A4'], ['G4'], ['A4'], ['A4'], ['A4'], ['F#5'], ['F#5'], ['D4', 'D5'], ['D5'], ['E4', 'D5'], ['E4', 'G4'], ['E4', 'A4'], ['E4', 'A4'], ['E4', 'F#5'], ['E4'], ['D5'], ['G4'], ['A4'], ['A4'], ['A4'], ['A4'], ['G4'], ['A4'], ['A4'], ['A4'], ['F#5'], ['F#5'], ['D4', 'D5'], ['D5'], ['E4', 'D5'], ['E4', 'G4'], ['E4', 'A4'], ['E4', 'A4'], ['E4', 'G5'], ['E4'], ['F#5'], ['D5'], ['E5'], ['E5'], ['E5'], ['E5'], ['C#5', 'E5'], ['C#5', 'E5'], ['C#5', 'E5'], ['E5'], ['F#5'], ['F#5'], ['F#5'], ['G5'], ['B4', 'E5'], ['B4', 'E5'], ['B4', 'E5'], ['E5'], ['F#5'], ['F#5'], ['G5'], ['G5'], ['A4', 'E5', 'A5'], ['A4', 'E5', 'A5'], ['A4', 'E5', 'A5'], ['A4', 'E5', 'A5'], ['E5', 'A5'], ['A5'], ['D5', 'B5'], ['D5', 'B5'], ['B5'], ['D5', 'A5'], ['D5', 'A5'], ['D5', 'A5'], ['A5'], ['D5'], ['C#5'], ['D5'], ['A5'], ['A5'], ['A5'], ['C#5'], ['B4'], ['B4'], ['B4'], ['B4'], ['C#5'], ['B4'], ['B4'], ['A4', 'A5'], ['A4', 'D5'], ['D5'], ['D5'], ['A4'], ['A4'], ['A4'], ['D4', 'A4'], ['A4'], ['F#4', 'D5'], ['F#4', 'D5'], ['F#4', 'D5'], ['D5'], ['F#4', 'C#5'], ['C#5'], ['D5'], ['A4'], ['A4'], ['A4'], ['D4'], ['D4', 'C#5'], ['D4', 'C#5'], ['C#5'], ['D5'], ['D5'], ['D4', 'B4'], ['D4', 'B4'], ['D4', 'B4'], ['B4'], ['A4'], ['B4'], ['C#5'], ['D5'], ['D5'], ['D4', 'D5'], ['D4', 'C#5'], ['D4', 'D5'], ['D4'], ['D4'], ['E4', 'A4'], ['E4', 'A4'], ['E4', 'A4'], ['A4'], ['D4'], ['F#4'], ['F#4'], ['G4'], ['G4'], ['E4'], ['E4'], ['C#4'], ['C#4'], ['D4', 'F#5'], ['A4', 'F#5'], ['D5', 'F#5'], ['D5'], ['D5'], ['D5'], ['D5'], ['E5', 'A5'], ['E4', 'E5', 'A5'], ['E5', 'A5'], ['A5'], ['A4', 'D5'], ['A4'], ['F#5'], ['F#4', 'F#5'], ['F#4'], ['F#4'], ['F#5'], ['F#4', 'F#5'], ['F#5'], ['B4', 'D5'], ['B4'], ['F#5'], ['D4'], ['B4'], ['B4', 'B5'], ['B4'], ['E5', 'A5'], ['D4', 'E5', 'A5'], ['D4', 'A5'], ['D4', 'D5'], ['D4', 'E5'], ['D4', 'F#5'], ['D4'], ['D5'], ['D4', 'D5'], ['D4', 'B4'], ['D4'], ['D4', 'A4'], ['D4', 'A4'], ['A4'], ['D4'], ['E4'], ['F#4'], ['D4'], ['D5'], ['D5'], ['C#5'], ['D5'], ['D5'], ['D5'], ['F#4'], ['F#4'], ['D5'], ['A5'], ['D5', 'A5'], ['A5']]\n",
            "[['D4', 'G5'], ['A5'], ['A5'], ['A4'], ['A4'], ['D5'], ['A4', 'D5'], ['D5', 'E5'], ['A4', 'D5'], ['D5'], ['D5', 'G5'], ['D5', 'A5'], ['D5', 'A5'], ['D5', 'G5'], ['D5', 'G5'], ['D4', 'G5'], ['D4', 'A5'], ['A4', 'A5'], ['D4', 'A4'], ['B4'], ['B4'], ['D4', 'G5'], ['D4', 'A5'], ['A4', 'A5'], ['A4', 'A5'], ['A4', 'A5'], ['A4', 'D5'], ['A4', 'D5'], ['A4', 'D5'], ['A4', 'D5', 'E5'], ['A4', 'D5', 'E5'], ['D5', 'G5'], ['D5', 'G5'], [], [], [], [], [], ['D4'], ['D4'], [], [], [], [], [], ['E4'], ['A4'], ['A4'], ['A4'], ['A4'], ['A4'], ['E4'], ['B4'], ['B4'], ['B4'], ['D4'], ['A4'], ['A4'], ['A4'], ['A4'], ['A4'], ['D4'], ['B4'], ['B4'], ['F#4'], ['B4'], ['B4'], ['B4'], ['B4'], ['B4'], ['E4'], ['A4'], ['A4'], ['B5'], ['D4', 'B5'], ['A4', 'B5'], ['A4', 'B5'], ['A4', 'B5'], ['A4', 'A5'], ['A4', 'B5'], ['D4'], ['A4'], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], [], []]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:128: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbVKzSJ6GhoE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}